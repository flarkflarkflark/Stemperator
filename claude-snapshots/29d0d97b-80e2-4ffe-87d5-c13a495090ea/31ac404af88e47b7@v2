#include "GPUBackend.h"
#include <juce_core/juce_core.h>

namespace GPUBackend
{
    //==============================================================================
    // Global state
    static bool g_initialized = false;
    static std::string g_lastError;
    static DeviceInfo g_deviceInfo;

    #if defined(GPU_BACKEND_OPENCL)
        static cl_context g_clContext = nullptr;
        static cl_command_queue g_clQueue = nullptr;
        static cl_device_id g_clDevice = nullptr;
    #elif defined(GPU_BACKEND_CUDA)
        static int g_cudaDevice = 0;
    #elif defined(GPU_BACKEND_HIP)
        static int g_hipDevice = 0;
    #elif defined(GPU_BACKEND_VULKAN)
        static VkInstance g_vkInstance = VK_NULL_HANDLE;
        static VkDevice g_vkDevice = VK_NULL_HANDLE;
        static VkPhysicalDevice g_vkPhysicalDevice = VK_NULL_HANDLE;
    #endif

    //==============================================================================
    bool initialize()
    {
        if (g_initialized)
            return true;

        juce::Logger::writeToLog("GPU Backend: Initializing...");

        #if defined(GPU_BACKEND_OPENCL)
            // OpenCL initialization
            cl_int err;
            cl_platform_id platform;
            cl_uint numPlatforms;

            err = clGetPlatformIDs(1, &platform, &numPlatforms);
            if (err != CL_SUCCESS || numPlatforms == 0)
            {
                g_lastError = "No OpenCL platforms found";
                juce::Logger::writeToLog("GPU Backend: " + g_lastError);
                return false;
            }

            err = clGetDeviceIDs(platform, CL_DEVICE_TYPE_GPU, 1, &g_clDevice, nullptr);
            if (err != CL_SUCCESS)
            {
                g_lastError = "No OpenCL GPU devices found";
                juce::Logger::writeToLog("GPU Backend: " + g_lastError);
                return false;
            }

            g_clContext = clCreateContext(nullptr, 1, &g_clDevice, nullptr, nullptr, &err);
            if (err != CL_SUCCESS)
            {
                g_lastError = "Failed to create OpenCL context";
                return false;
            }

            #if defined(CL_VERSION_2_0)
                g_clQueue = clCreateCommandQueueWithProperties(g_clContext, g_clDevice, nullptr, &err);
            #else
                g_clQueue = clCreateCommandQueue(g_clContext, g_clDevice, 0, &err);
            #endif

            if (err != CL_SUCCESS)
            {
                g_lastError = "Failed to create OpenCL command queue";
                clReleaseContext(g_clContext);
                return false;
            }

            // Get device info
            char deviceName[256];
            char vendor[256];
            cl_ulong globalMem;
            cl_uint computeUnits;
            size_t maxWorkGroupSize;

            clGetDeviceInfo(g_clDevice, CL_DEVICE_NAME, sizeof(deviceName), deviceName, nullptr);
            clGetDeviceInfo(g_clDevice, CL_DEVICE_VENDOR, sizeof(vendor), vendor, nullptr);
            clGetDeviceInfo(g_clDevice, CL_DEVICE_GLOBAL_MEM_SIZE, sizeof(cl_ulong), &globalMem, nullptr);
            clGetDeviceInfo(g_clDevice, CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(cl_uint), &computeUnits, nullptr);
            clGetDeviceInfo(g_clDevice, CL_DEVICE_MAX_WORK_GROUP_SIZE, sizeof(size_t), &maxWorkGroupSize, nullptr);

            g_deviceInfo.name = deviceName;
            g_deviceInfo.vendor = vendor;
            g_deviceInfo.totalMemory = globalMem;
            g_deviceInfo.availableMemory = globalMem; // Simplified
            g_deviceInfo.computeUnits = computeUnits;
            g_deviceInfo.maxWorkGroupSize = static_cast<int>(maxWorkGroupSize);
            g_deviceInfo.backendName = "OpenCL";

            g_initialized = true;
            juce::Logger::writeToLog("GPU Backend: OpenCL initialized (" + g_deviceInfo.name + ")");
            return true;

        #elif defined(GPU_BACKEND_CUDA)
            // CUDA initialization
            cudaError_t err = cudaSetDevice(0);
            if (err != cudaSuccess)
            {
                g_lastError = "CUDA device not found";
                return false;
            }

            cudaDeviceProp prop;
            cudaGetDeviceProperties(&prop, 0);

            g_deviceInfo.name = prop.name;
            g_deviceInfo.vendor = "NVIDIA";
            g_deviceInfo.totalMemory = prop.totalGlobalMem;
            g_deviceInfo.availableMemory = prop.totalGlobalMem;
            g_deviceInfo.computeUnits = prop.multiProcessorCount;
            g_deviceInfo.maxWorkGroupSize = prop.maxThreadsPerBlock;
            g_deviceInfo.backendName = "CUDA";

            g_initialized = true;
            juce::Logger::writeToLog("GPU Backend: CUDA initialized (" + g_deviceInfo.name + ")");
            return true;

        #elif defined(GPU_BACKEND_HIP)
            // HIP initialization
            hipError_t err = hipSetDevice(0);
            if (err != hipSuccess)
            {
                g_lastError = "HIP device not found";
                return false;
            }

            hipDeviceProp_t prop;
            hipGetDeviceProperties(&prop, 0);

            g_deviceInfo.name = prop.name;
            g_deviceInfo.vendor = "AMD";
            g_deviceInfo.totalMemory = prop.totalGlobalMem;
            g_deviceInfo.availableMemory = prop.totalGlobalMem;
            g_deviceInfo.computeUnits = prop.multiProcessorCount;
            g_deviceInfo.maxWorkGroupSize = prop.maxThreadsPerBlock;
            g_deviceInfo.backendName = "ROCm/HIP";

            g_initialized = true;
            juce::Logger::writeToLog("GPU Backend: ROCm/HIP initialized (" + g_deviceInfo.name + ")");
            return true;

        #elif defined(GPU_BACKEND_VULKAN)
            // Vulkan initialization
            // TODO: Implement Vulkan initialization
            g_lastError = "Vulkan backend not yet implemented";
            return false;

        #elif defined(GPU_BACKEND_ONEAPI)
            // Intel oneAPI initialization
            // TODO: Implement oneAPI initialization
            g_lastError = "oneAPI backend not yet implemented";
            return false;

        #else
            g_lastError = "No GPU backend compiled";
            return false;
        #endif
    }

    void shutdown()
    {
        if (!g_initialized)
            return;

        #if defined(GPU_BACKEND_OPENCL)
            if (g_clQueue) clReleaseCommandQueue(g_clQueue);
            if (g_clContext) clReleaseContext(g_clContext);
            g_clQueue = nullptr;
            g_clContext = nullptr;
            g_clDevice = nullptr;
        #elif defined(GPU_BACKEND_CUDA)
            cudaDeviceReset();
        #elif defined(GPU_BACKEND_HIP)
            hipDeviceReset();
        #endif

        g_initialized = false;
        juce::Logger::writeToLog("GPU Backend: Shutdown");
    }

    bool isAvailable()
    {
        return g_initialized;
    }

    DeviceInfo getDeviceInfo()
    {
        return g_deviceInfo;
    }

    std::string getBackendName()
    {
        #if defined(GPU_BACKEND_OPENCL)
            return "OpenCL";
        #elif defined(GPU_BACKEND_CUDA)
            return "CUDA";
        #elif defined(GPU_BACKEND_HIP)
            return "ROCm/HIP";
        #elif defined(GPU_BACKEND_VULKAN)
            return "Vulkan";
        #elif defined(GPU_BACKEND_ONEAPI)
            return "oneAPI";
        #else
            return "None";
        #endif
    }

    void synchronize()
    {
        #if defined(GPU_BACKEND_OPENCL)
            if (g_clQueue)
                clFinish(g_clQueue);
        #elif defined(GPU_BACKEND_CUDA)
            cudaDeviceSynchronize();
        #elif defined(GPU_BACKEND_HIP)
            hipDeviceSynchronize();
        #endif
    }

    std::string getLastError()
    {
        return g_lastError;
    }

    //==============================================================================
    // GPUBuffer implementation
    //==============================================================================
    GPUBuffer::~GPUBuffer()
    {
        release();
    }

    bool GPUBuffer::allocate(size_t sizeInBytes)
    {
        release();

        size = sizeInBytes;

        #if defined(GPU_BACKEND_OPENCL)
            cl_int err;
            nativeBuffer = clCreateBuffer(g_clContext, CL_MEM_READ_WRITE, sizeInBytes, nullptr, &err);
            return (err == CL_SUCCESS);
        #elif defined(GPU_BACKEND_CUDA)
            return (cudaMalloc(&nativeBuffer, sizeInBytes) == cudaSuccess);
        #elif defined(GPU_BACKEND_HIP)
            return (hipMalloc(&nativeBuffer, sizeInBytes) == hipSuccess);
        #else
            return false;
        #endif
    }

    bool GPUBuffer::upload(const void* hostData, size_t sizeInBytes)
    {
        if (!nativeBuffer || sizeInBytes > size)
            return false;

        #if defined(GPU_BACKEND_OPENCL)
            cl_int err = clEnqueueWriteBuffer(g_clQueue, static_cast<cl_mem>(nativeBuffer),
                                             CL_TRUE, 0, sizeInBytes, hostData, 0, nullptr, nullptr);
            return (err == CL_SUCCESS);
        #elif defined(GPU_BACKEND_CUDA)
            return (cudaMemcpy(nativeBuffer, hostData, sizeInBytes, cudaMemcpyHostToDevice) == cudaSuccess);
        #elif defined(GPU_BACKEND_HIP)
            return (hipMemcpy(nativeBuffer, hostData, sizeInBytes, hipMemcpyHostToDevice) == hipSuccess);
        #else
            return false;
        #endif
    }

    bool GPUBuffer::download(void* hostData, size_t sizeInBytes)
    {
        if (!nativeBuffer || sizeInBytes > size)
            return false;

        #if defined(GPU_BACKEND_OPENCL)
            cl_int err = clEnqueueReadBuffer(g_clQueue, static_cast<cl_mem>(nativeBuffer),
                                            CL_TRUE, 0, sizeInBytes, hostData, 0, nullptr, nullptr);
            return (err == CL_SUCCESS);
        #elif defined(GPU_BACKEND_CUDA)
            return (cudaMemcpy(hostData, nativeBuffer, sizeInBytes, cudaMemcpyDeviceToHost) == cudaSuccess);
        #elif defined(GPU_BACKEND_HIP)
            return (hipMemcpy(hostData, nativeBuffer, sizeInBytes, hipMemcpyDeviceToHost) == hipSuccess);
        #else
            return false;
        #endif
    }

    void GPUBuffer::release()
    {
        if (nativeBuffer)
        {
            #if defined(GPU_BACKEND_OPENCL)
                clReleaseMemObject(static_cast<cl_mem>(nativeBuffer));
            #elif defined(GPU_BACKEND_CUDA)
                cudaFree(nativeBuffer);
            #elif defined(GPU_BACKEND_HIP)
                hipFree(nativeBuffer);
            #endif

            nativeBuffer = nullptr;
            size = 0;
        }
    }

    //==============================================================================
    // GPUFFT implementation
    //==============================================================================
    GPUFFT::~GPUFFT()
    {
        release();
    }

    bool GPUFFT::createPlan(int fftSizeParam, int batchSizeParam)
    {
        fftSize = fftSizeParam;
        batchSize = batchSizeParam;

        #if defined(GPU_BACKEND_CUDA)
            cufftResult result = cufftPlan1d(reinterpret_cast<cufftHandle*>(&fftPlan),
                                            fftSize, CUFFT_R2C, batchSize);
            return (result == CUFFT_SUCCESS);
        #elif defined(GPU_BACKEND_HIP)
            rocfft_status status = rocfft_plan_create(reinterpret_cast<rocfft_plan*>(&fftPlan),
                                                     rocfft_placement_notinplace,
                                                     rocfft_transform_type_real_forward,
                                                     rocfft_precision_single,
                                                     1, // 1D FFT
                                                     reinterpret_cast<size_t*>(&fftSize),
                                                     batchSize,
                                                     nullptr);
            return (status == rocfft_status_success);
        #elif defined(GPU_BACKEND_OPENCL)
            // TODO: Implement clFFT plan creation
            return false;
        #else
            return false;
        #endif
    }

    bool GPUFFT::executeForward(GPUBuffer& input, GPUBuffer& output)
    {
        #if defined(GPU_BACKEND_CUDA)
            cufftResult result = cufftExecR2C(reinterpret_cast<cufftHandle>(fftPlan),
                                             static_cast<cufftReal*>(input.getNativeHandle()),
                                             static_cast<cufftComplex*>(output.getNativeHandle()));
            return (result == CUFFT_SUCCESS);
        #elif defined(GPU_BACKEND_HIP)
            // TODO: Execute rocFFT
            return false;
        #else
            return false;
        #endif
    }

    bool GPUFFT::executeInverse(GPUBuffer& input, GPUBuffer& output)
    {
        #if defined(GPU_BACKEND_CUDA)
            cufftResult result = cufftExecC2R(reinterpret_cast<cufftHandle>(fftPlan),
                                             static_cast<cufftComplex*>(input.getNativeHandle()),
                                             static_cast<cufftReal*>(output.getNativeHandle()));
            return (result == CUFFT_SUCCESS);
        #elif defined(GPU_BACKEND_HIP)
            // TODO: Execute rocFFT inverse
            return false;
        #else
            return false;
        #endif
    }

    void GPUFFT::release()
    {
        if (fftPlan)
        {
            #if defined(GPU_BACKEND_CUDA)
                cufftDestroy(reinterpret_cast<cufftHandle>(fftPlan));
            #elif defined(GPU_BACKEND_HIP)
                rocfft_plan_destroy(reinterpret_cast<rocfft_plan>(fftPlan));
            #endif

            fftPlan = nullptr;
        }
    }

    //==============================================================================
    // GPUKernel implementation (stub for now)
    //==============================================================================
    GPUKernel::~GPUKernel()
    {
        release();
    }

    bool GPUKernel::loadFromSource(const std::string& kernelSource, const std::string& kernelName)
    {
        // TODO: Implement kernel compilation for each backend
        return false;
    }

    bool GPUKernel::setArgument(int index, GPUBuffer& buffer)
    {
        // TODO: Implement argument setting
        return false;
    }

    bool GPUKernel::setArgument(int index, float value)
    {
        // TODO: Implement argument setting
        return false;
    }

    bool GPUKernel::setArgument(int index, int value)
    {
        // TODO: Implement argument setting
        return false;
    }

    bool GPUKernel::execute(size_t globalWorkSize, size_t localWorkSize)
    {
        // TODO: Implement kernel execution
        return false;
    }

    void GPUKernel::release()
    {
        // TODO: Implement resource cleanup
    }

} // namespace GPUBackend
